{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53aabbc5-324a-4c07-9451-099eb406a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "from tensorflow.keras import models\n",
    "import turtle\n",
    "import webrtcvad\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25eaa5c9-5964-494e-a34b-76b591c85c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK_DURATION_MS = 30  # Размер фрейма в миллисекундах\n",
    "PADDING_DURATION_MS = 300  # Дополнительная длительность окна в миллисекундах\n",
    "FRAME_SIZE = int(RATE * CHUNK_DURATION_MS / 1000)  # Размер фрейма в сэмплах\n",
    "NUM_PADDING_FRAMES = int(RATE * PADDING_DURATION_MS / 1000 / FRAME_SIZE)  # Количество дополнительных фреймов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09a7b916-23ca-4d10-83db-8376ad893468",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Frame(object):\n",
    "    \"\"\"Represents a \"frame\" of audio data.\"\"\"\n",
    "    def __init__(self, bytes, timestamp, duration):\n",
    "        self.bytes = bytes\n",
    "        self.timestamp = timestamp\n",
    "        self.duration = duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30c44c0c-fa7f-4d88-92d1-18292af2b824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vad_collector(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames):\n",
    "    \"\"\"Фильтрует аудиофреймы, оставляя только голосовые.\n",
    "\n",
    "    Принимает экземпляр webrtcvad.Vad и поток аудиофреймов.\n",
    "\n",
    "    Возвращает сегменты голоса, разделенные молчаниями.\n",
    "    \"\"\"\n",
    "    num_padding_frames = int(padding_duration_ms / frame_duration_ms)\n",
    "    ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
    "    triggered = False\n",
    "\n",
    "    voiced_frames = []\n",
    "    for frame in frames:\n",
    "        is_speech = vad.is_speech(frame.bytes, sample_rate)\n",
    "        if not triggered:\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "            if num_voiced > 0.9 * ring_buffer.maxlen:\n",
    "                triggered = True\n",
    "                for f, s in ring_buffer:\n",
    "                    voiced_frames.append(f)\n",
    "                ring_buffer.clear()\n",
    "        else:\n",
    "            voiced_frames.append(frame)\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
    "            if num_unvoiced > 0.9 * ring_buffer.maxlen:\n",
    "                triggered = False\n",
    "                yield b''.join([f.bytes for f in voiced_frames])\n",
    "                ring_buffer.clear()\n",
    "                voiced_frames = []\n",
    "    if triggered:\n",
    "        yield b''.join([f.bytes for f in voiced_frames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3402e22-b2a9-4bf1-a31c-4b51e0c06ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio():\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=FRAME_SIZE)\n",
    "    print(\"Listening...\")\n",
    "\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            data = stream.read(FRAME_SIZE)\n",
    "            frames.append(data)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    print(\"Recording stopped.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aff7d77-b399-4473-8bf9-c9521817dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_command_from_microphone():\n",
    "    vad = webrtcvad.Vad(2)  # Уровень агрессивности VAD (1-3)\n",
    "    frames = record_audio()\n",
    "    frames = [np.frombuffer(frame, dtype=np.int16) for frame in frames]\n",
    "    frames = [Frame(frame, None, None) for frame in frames]\n",
    "    segments = vad_collector(RATE, CHUNK_DURATION_MS, PADDING_DURATION_MS, vad, frames)\n",
    "    waveform = b''.join(segments)\n",
    "    # Здесь вы можете передать сегмент аудио на предсказание команды черепашке\n",
    "    \n",
    "    \n",
    "    spec = preprocess_audiobuffer(audio)\n",
    "    prediction = model(spec)\n",
    "    print(prediction)\n",
    "    confidence = np.max(tf.nn.softmax(prediction))\n",
    "    print('Confidence: ', confidence)\n",
    "    if confidence < 0.8:\n",
    "        print(\"Недостаточно уверенное предсказание. Пропускаем.\")\n",
    "        label_pred = np.argmax(prediction, axis=1)\n",
    "        print(label_pred)\n",
    "        command = commands[label_pred[0]]\n",
    "        print('Predicted label: ', command)\n",
    "        return None\n",
    "    label_pred = np.argmax(prediction, axis=1)\n",
    "    print(label_pred)\n",
    "    command = commands[label_pred[0]]\n",
    "    print('Predicted label: ', command)\n",
    "    return command\n",
    "    # return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a952334e-bab6-4e3b-ab53-d3e9d72516c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audiobuffer(waveform):\n",
    "    waveform = waveform / 32768\n",
    "    waveform = tf.convert_to_tensor(waveform, dtype=tf.float32)\n",
    "    spectrogram = get_spectrogram(waveform)\n",
    "    spectrogram=tf.expand_dims(spectrogram, 0)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1ea2d8b-6511-4536-8d7b-72f8d903e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform):\n",
    "    input_len = 16000\n",
    "    waveform = waveform[:input_len]\n",
    "    zero_padding = tf.zeros(\n",
    "        [input_len] - tf.shape(waveform),\n",
    "        dtype=tf.float32)\n",
    "    waveform = tf.cast(waveform, dtype=tf.float32)\n",
    "    equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "    spectrogram = tf.signal.stft(\n",
    "        equal_length, frame_length=255, frame_step=128)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = spectrogram[..., tf.newaxis]\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e8bba7a-3a52-4153-b380-b435265e4c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "commands = ['down', 'go', 'left', 'right', 'stop', 'up']\n",
    "model = models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fd2245-4599-4785-a491-816705986326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b9181e-d2dc-4462-85c8-67cc38eb1d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9f60663-db01-450c-b868-9322f6cd98af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Recording stopped.\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Error while processing frame",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-ea238c7e8bef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_command_from_microphone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcommand\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-ea18c20d74f1>\u001b[0m in \u001b[0;36mget_command_from_microphone\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0msegments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvad_collector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRATE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCHUNK_DURATION_MS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPADDING_DURATION_MS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mwaveform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Здесь вы можете передать сегмент аудио на предсказание команды черепашке\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-f54d6903a909>\u001b[0m in \u001b[0;36mvad_collector\u001b[1;34m(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mvoiced_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mis_speech\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_speech\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtriggered\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mring_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_speech\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sergeysaber\\pyver\\py392\\lib\\site-packages\\webrtcvad.py\u001b[0m in \u001b[0;36mis_speech\u001b[1;34m(self, buf, sample_rate, length)\u001b[0m\n\u001b[0;32m     25\u001b[0m                 'buffer has %s frames, but length argument was %s' % (\n\u001b[0;32m     26\u001b[0m                     int(len(buf) / 2.0), length))\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_webrtcvad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mError\u001b[0m: Error while processing frame"
     ]
    }
   ],
   "source": [
    "s = turtle.getscreen()\n",
    "\n",
    "t = turtle.Turtle() # starts at right:\n",
    "\n",
    "size = t.turtlesize()\n",
    "increase = (2 * num for num in size)\n",
    "t.turtlesize(*increase)\n",
    "\n",
    "t.pensize(5)\n",
    "t.shapesize()\n",
    "t.pencolor(\"blue\")\n",
    "\n",
    "def go_right():\n",
    "    # target = 0\n",
    "    current = t.heading()\n",
    "    if current == 0:\n",
    "        pass\n",
    "    elif current == 90:\n",
    "        t.right(90)\n",
    "    elif current == 180:\n",
    "        t.right(180)\n",
    "    elif current == 270:\n",
    "        t.left(90)\n",
    "    else:\n",
    "        raise ValueError('not a right angle!')\n",
    "\n",
    "def go_up():\n",
    "    # target = 90\n",
    "    current = t.heading()\n",
    "    if current == 0:\n",
    "        t.left(90)\n",
    "    elif current == 90:\n",
    "        pass\n",
    "    elif current == 180:\n",
    "        t.right(90)\n",
    "    elif current == 270:\n",
    "        t.left(180)\n",
    "    else:\n",
    "        raise ValueError('not a right angle!')\n",
    "    \n",
    "def go_left():\n",
    "    # target = 180\n",
    "    current = t.heading()\n",
    "    if current == 0:\n",
    "        t.left(180)\n",
    "    elif current == 90:\n",
    "        t.left(90)\n",
    "    elif current == 180:\n",
    "        pass\n",
    "    elif current == 270:\n",
    "        t.right(90)\n",
    "    else:\n",
    "        raise ValueError('not a right angle!')\n",
    "    \n",
    "def go_down():\n",
    "    # target = 270\n",
    "    current = t.heading()\n",
    "    if current == 0:\n",
    "        t.right(90)\n",
    "    elif current == 90:\n",
    "        t.right(180)\n",
    "    elif current == 180:\n",
    "        t.left(90)\n",
    "    elif current == 270:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('not a right angle!')\n",
    "\n",
    "\n",
    "def move_turtle(command):\n",
    "    if command == 'up':\n",
    "        go_up()\n",
    "    elif command == 'down':\n",
    "        go_down()\n",
    "    elif command == 'left':\n",
    "        go_left()\n",
    "    elif command == 'right':\n",
    "        go_right()\n",
    "    elif command == 'go':\n",
    "        t.forward(100)\n",
    "    elif command == 'stop':\n",
    "        s.bye()\n",
    "        print('Stopping the turtle')\n",
    "\n",
    "while True:\n",
    "    command = get_command_from_microphone()\n",
    "    if command is None:\n",
    "        continue\n",
    "    move_turtle(command)\n",
    "    if command == \"stop\":\n",
    "        terminate()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
